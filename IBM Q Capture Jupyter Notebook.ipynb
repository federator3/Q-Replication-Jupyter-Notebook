{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  IBM Q Capture Jupyter Notebook\n",
    "Author: Christian Lenke, IBM<br>\n",
    "Version: 2020-11-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "\n",
    "* [Preface](#intro)\n",
    "* [Introduction](#intro)\n",
    "<p>\n",
    "* [Installation, import, function definition](#preparation)\n",
    "  * [Environment Definition and Customization](#customization)\n",
    "  * [Get a connection to the Q Capture Server](#connect_qcap)\n",
    "<p>\n",
    "* [Q Capture Status overview](#overview_qcap)\n",
    "  * [General Q Capture overview](#overview_qcap)\n",
    "  * [Send Queue state](#sendq)\n",
    "  * [Q Subscriptions by Send Queue](#qsubs_sendq)    \n",
    "<p>\n",
    "* [Q Capture performance graphs](#qcap_performance)\n",
    "  * [Log Reader statistics](#qcap_performance)    \n",
    "  * [Publisher statistics](#qcap_publ)        \n",
    "<p>\n",
    "* [Status details](#qcap_details)\n",
    "  * [Send Queue details](#qcap_details)\n",
    "  * [Q Subscription details](#qsubs_details)\n",
    "  * [Q Subscription quality assurance](#qsubs_qa)        \n",
    "<p>\n",
    "* [Q Capture Control Tables](#qcap_cntl)\n",
    "  * [CAPPARMS](#qcap_cntl)\n",
    "  * [CAPMON and CAPQMON](#qcap_mon)\n",
    "  * [CAPTRACE](#qcap_trace)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is sample code. No warranty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set of Jupyter Notebook can be used to display status, performance, and health of an IBM Q Replication setup. The following components are provided:\n",
    " <ul>\n",
    "  <li>Q Capture Jupyter Notebook (this Notebook)</li>\n",
    "  <li>Q Apply Jupyter Notebook</li>\n",
    "  <li>Q Replication function library Jupyter Notebook</li>\n",
    "  <li>A set of SQL queries in files (asnmonitor) for status calculation and quality assurance</li>    \n",
    "</ul> \n",
    "The Notebooks display the content of the IBM Q Replication control tables. This includes an overall health summary for both Q Capture and Q Apply, performance graphs (throughput, latency, etc.), and control table details for both queues and subscriptions.<br>\n",
    "Start with the following:<br>\n",
    " <ol>\n",
    "  <li>Copy the set of SQL query files to a location in your environment</li>\n",
    "  <li>Cuctomize some of the SQL files depending on your environment (more details in the Q Replication function library Notebook)</li>\n",
    "  <li>Customize the Q Replication function library (details explained in that Notebook)</li>\n",
    "  <li>Customize the Q Capture and Q Apply Notebook (this Notebook) in section \"Environment Definition and Customization\" \n",
    "</ol> \n",
    "To better understand the Q Replication control tables and the SQL queries used, have a look at<br>\n",
    "<A HREF=\"https://developer.ibm.com/recipes/tutorials/q-replication-for-dbas/\">Q Replication for DBAs</A>,<br> \n",
    "<A HREF=\"https://www.ibm.com/support/knowledgecenter/en/SSTRGZ_11.4.0/com.ibm.swg.im.iis.repl.qrepl.doc/topics/iiyrqctbrcaplist.html\">Control tables at the Q Capture server</A>,<br> \n",
    "<A HREF=\"https://www.ibm.com/support/knowledgecenter/en/SSTRGZ_11.4.0/com.ibm.swg.im.iis.repl.qrepl.doc/topics/iiyrqctbrapplist.html\">Control tables at the Q Apply server</A>, or <br>\n",
    "<A HREF=\"https://www.ibm.com/support/knowledgecenter/en/SSTRGZ_11.4.0/com.ibm.swg.im.iis.db.repl.intro.doc/topics/iiyrqinfroadmap.html\">Q Replication Information Roadmap (IBM Knowledge Center)</A>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation, import, function definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all the \"IBM Q Replication Monitoring Jupyter Library.ipynb\" is run. It imports all required libraries (SQLAlchemy, pandas, pixiedust, ...) and defines functions used in this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"IBM Q Replication Monitoring Jupyter Library.ipynb\"\n",
    "# from sqlalchemy import exc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='customization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Definition and Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEFORE YOU START define your environment here. Specify your individual values for all variables in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your Q Capture Schema. All queries selecting data from the Q Replication control tables \n",
    "# have been coded schemaless, the schema needs to be declared once here.\n",
    "capture_schema = 'ASN'\n",
    "# capture_schema = 'LSN'\n",
    "\n",
    "# Database alias of the Q Capture Server (Db2 LUW database name or Db2 z/OS location name)\n",
    "db2alias = 'SOURCEDB'\n",
    "\n",
    "# Setting the connection variables for the Q Capture server \n",
    "# (usually the Q Replication target database)\n",
    "db2_driver='ibm_db_sa'\n",
    "# Host name or ip-address of the Q Capture Server\n",
    "db2host  = 'localhost'\n",
    "# Db2 port of the Q Capture Server (defined as char)\n",
    "db2port  = 50000\n",
    "\n",
    "# User id privileged to read the Q Capture control tables\n",
    "db2user  = 'REPLADMIN'\n",
    "# You will be prompted to type in your password\n",
    "db2password = getpass.getpass('Password for database ' + db2alias + ': '); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to control debug messages. False: No debug messages; True: Some debug messages will be printed\n",
    "# debug = True\n",
    "debug = False\n",
    "\n",
    "# Display all columns when showing a data frame\n",
    "pandas.set_option('display.max_columns', None)\n",
    "\n",
    "# Define the date range for plotting performance data from IBMQREP_CAPMON and IBMQREP_CAPQMON \n",
    "# (plots grouped by hour)\n",
    "# Default: 60 (Retrieve only 60 days of Monitor data for plotting)\n",
    "# If you want to retrieve all available data, set max_mon_plot_range = -1\n",
    "# max_mon_plot_range = -1\n",
    "max_mon_plot_range = 60\n",
    "\n",
    "# Define the number of most recent messages messages to be retrieved from IBMQREP_CAPTRACE\n",
    "# If you want to retrieve all available data, set num_messages_trace = -1\n",
    "# num_messages_trace = -1\n",
    "num_messages_trace = 200\n",
    "\n",
    "# Define the date range for fetching monitor information from IBMQREP_CAPMON and IBMQREP_CAPQMON\n",
    "# Default data rage in number of days, negative number, e.g. -5 (last n days of monitoring data)\n",
    "default_mon_date_range = 10\n",
    "\n",
    "# Custom range: -1 means from oldest available (start) to most recent (end).\n",
    "# Alternatively, specify timestamp in Db2 format\n",
    "# custom_mon_start_date  = '2018-11-02-10.00.00.000000'\n",
    "custom_mon_start_date  = -1\n",
    "custom_mon_end_date    = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the validity of some parms\n",
    "check_minus_1_or_positive_int('max_mon_plot_range', max_mon_plot_range)        \n",
    "check_minus_1_or_positive_int('num_messages_trace', num_messages_trace)        \n",
    "check_positive_int('default_mon_date_range', default_mon_date_range) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='connect_qcap'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a connection to the Q Capture Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Q Capture Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = get_connection(db2_driver, db2user, db2password, db2host, str(db2port), db2alias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the CURRENT SCHEMA to the CAPTURE_SCHEMA. All queries executed thereafter are schemaless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the connection the SCHEMA is set to the Q Capture schema\n",
    "connection.execute(\"SET CURRENT SCHEMA = '\" + capture_schema + \"'\")\n",
    "\n",
    "print(\"INFO: CURRENT SCHEMA = '\" + capture_schema + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='overview_qcap'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Capture Status overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General status overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first query displays the overall status of the Q Capture Server. The result set displays messages of the following types:\n",
    " <ul>\n",
    "  <li>C-LAT: Is Q Capture running or not / is the latency as expected (threshold needs to be set in 'qrep_monitor_capture.sql')</li>\n",
    "    <ul>    \n",
    "        <li>ERROR: Q Capture not running or latency error threshold exceeded</li>\n",
    "        <li>WARNING: Q Capture latency warning threshold exceeded</li>\n",
    "        <li>INFO: Q Capture up and running and latency threshold ok</li>        \n",
    "    </ul>            \n",
    "  <li>C-SQU: Send queue status, displayed for each send queue.</li>\n",
    "    <ul>    \n",
    "        <li>ERROR: Send Queue inactive due to an error</li>\n",
    "        <li>INFO: Send Queue active</li>            \n",
    "    </ul>                    \n",
    "  <li>S-SUB: Summary whether all subscriptions for a queue are active or not, displayed for each send queue.</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_capture_status executes the query 'qrep_monitor_capture.sql' \n",
    "# (with language dependent result set) and returns a pandas data frame\n",
    "df_capstate = get_capture_status(connection)\n",
    "\n",
    "# drop column 'CURRENT_SERVER'\n",
    "df_capstate.drop(df_capstate.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# conditional formatting for column 'sev'\n",
    "df_capstate = (df_capstate.style\n",
    "    .applymap(sev_background, subset=['sev'])\n",
    "    .applymap(sev_foreground, subset=['sev'])\n",
    ")\n",
    "\n",
    "# printing the data frame\n",
    "df_capstate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='sendq'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall send queue state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of active send queues (green) vs. number of inactive send queues (red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_sendq_state executes a query which counts active vs. inactive queues\n",
    "# and returns a pandas data frame\n",
    "df_qstate = get_sendq_state(connection)  \n",
    "\n",
    "df_qstate.set_index('queues',inplace=True)\n",
    "\n",
    "qpl = df_qstate.plot.barh(stacked=True,color=['green', 'red'], \n",
    "                          title=\"Active vs. inactive send queues\",\n",
    "                          figsize=(10,2))\n",
    "\n",
    "qpl.set_xlabel(\"Number of queues\")\n",
    "myvar = qpl.set_ylabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qsubs_sendq'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription STATE by send queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of active subscriptions (green) vs. number of inactive subscriptions (red) per send queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_substate_by_recvq executes a query which counts active vs. inactive queues\n",
    "# and returns a pandas data frame\n",
    "df_q = get_substate_by_sendq(connection)\n",
    "\n",
    "numqs = len(df_q.sendq.unique())\n",
    "if numqs >=20:\n",
    "    calc_fig_height = numqs / 2\n",
    "if numqs <=2:\n",
    "    calc_fig_height = numqs * 2\n",
    "else:\n",
    "    calc_fig_height =  numqs\n",
    "\n",
    "# NEXT: Adding labels (SENDQ) - does not work\n",
    "df_q.set_index('sendq',inplace=True) \n",
    "\n",
    "sqpl = df_q.plot.barh(stacked=True,color=['green', 'red'],\n",
    "                       title=\"Number or active vs. inactive subs per send queue\",\n",
    "                       figsize=(15,calc_fig_height))\n",
    "\n",
    "sqpl.set_xlabel(\"Number of subs\")\n",
    "myvar = sqpl.set_ylabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qcap_performance'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Capture Performance Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture Log Reader statistics per hour (rows_processed, current_memory, trans_spilled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following codes creates plots which display Q Replication log reader KPIs grouped by hour. First, all data available in IBMQREP_CAPMON is evaluated (can be limited with parameter <i>max_mon_plot_range</i>). Next, the most recent 20 days will be evaluated, lastly the most recent 5 days.<p>\n",
    "The plots show the maximum memory used in the particular hour, the summary of all rows  processed from the log, and the number of monster transactions (which exceeded Q Capture's MEMORY_LIMNIT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_perf_logrd executes a query which selects data from IBMQREP_CAPMON\n",
    "# and returns a pandas data frame. The CAPMON data is GROUPed BY hour(monitor_time)\n",
    "# by the query. In case max_mon_plot_range == 0, the query will retrieve all available data \n",
    "# from CAPMON. If max_mon_plot_range > 0, the CAPMON data will be limited to the recent\n",
    "# max_mon_plot_range days\n",
    "\n",
    "if max_mon_plot_range == -1:              \n",
    "    print('INFO: Evaluating all available CAPMON data') \n",
    "else:   \n",
    "    print('INFO: Limiting the CAPMON data to a maximum of ' + str(max_mon_plot_range) + ' days.')\n",
    "    \n",
    "capmon_logrd = get_perf_logrd(connection, max_mon_plot_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG - print sample data of the data frame retrieved from APPLYMON\n",
    "if debug:\n",
    "   print(capmon_logrd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: What if data fame is empty (test)\n",
    "\n",
    "# Determine the date of max(monitor_time). This is used when only a subset (e.g., most recent\n",
    "# 5 days of data) is displayed later. Could be that the Notebook is used to evaluate saved \n",
    "# CAPMON data, so that today() - n days would have no data. \n",
    "maxmontime = capmon_logrd['monitor_date'].max()\n",
    "maxmondate = datetime.strptime(maxmontime[:10], \"%Y-%m-%d\")\n",
    "\n",
    "minmontime = capmon_logrd['monitor_date'].min()\n",
    "minmondate = datetime.strptime(minmontime[:10], \"%Y-%m-%d\")\n",
    "\n",
    "print('INFO: CAPMON' + ' [' + str(minmondate)[:10] + ' - ' + str(maxmondate)[:10] + ']') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All available data from IBMQREP_CAPMON (max. <i>max_mon_plot_range</i> days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figure with all available data   \n",
    "\n",
    "# deltadays = 0 means all available data of the data frame\n",
    "deltadays = max_mon_plot_range\n",
    "\n",
    "if deltadays == -1:\n",
    "    print('INFO: Plotting range: All available data from ' + minmondate.strftime(\"%Y-%m-%d\") \n",
    "                                                           + ' up to ' + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "else:\n",
    "    print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                           + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                           + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "# The function plot_capmon creates a figure with 1 plot from the \n",
    "# data frame capmon_lat\n",
    "capmon_plt1 = plot_capmon(capmon_logrd,deltadays)\n",
    "capmon_plt1.show()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent 20 days from IBMQREP_CAPMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in - Same figure as above, with data of the last 20 days only (maxmondate - 20 days)\n",
    "\n",
    "# display 20 days of data only\n",
    "deltadays = 20\n",
    "# old: date_20_days_ago = date.today() - timedelta(days=deltadays)\n",
    "date_20_days_ago = maxmondate - timedelta(days=deltadays)\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "   print('DEBUG: date_20_days_ago.strftime(\"%m/%d/%Y\"): ' + date_20_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                       + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                       + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# New data frame - limited by the calculated data range \n",
    "#   - reset_index was introduced to guarantee xticks in the plot\n",
    "capmon_logrd_20 = capmon_logrd[capmon_logrd.monitor_date \n",
    "                               >= date_20_days_ago.strftime(\"%Y-%m-%d\")].reset_index(drop=True)  \n",
    "\n",
    "capmon_plt2 = plot_capmon(capmon_logrd_20,deltadays)\n",
    "capmon_plt2.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent 5 days from IBMQREP_CAPMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in - Same figure as above, with data of the last 5 days only (maxmondate - 5 days)\n",
    "\n",
    "# display 5 days of data only\n",
    "deltadays = 5\n",
    "\n",
    "# old: date_5_days_ago = date.today() - timedelta(days=deltadays)\n",
    "date_5_days_ago = maxmondate - timedelta(days=deltadays)\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "   print('DEBUG: date_5_days_ago.strftime(\"%m/%d/%Y\"): ' + date_20_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                       + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                       + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# New data frame - limited by the calculated data range \n",
    "#   - reset_index was introduced to guarantee xticks in the plot\n",
    "capmon_logrd_5 = capmon_logrd[capmon_logrd.monitor_date \n",
    "                              >= date_5_days_ago.strftime(\"%Y-%m-%d\")].reset_index(drop=True)  \n",
    "\n",
    "capmon_plt3 = plot_capmon(capmon_logrd_5,deltadays)\n",
    "capmon_plt3.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qcap_publ'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture Publisher statistics per hour (rows_processed, mq_messages ,xmitqdepth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following codes creates plots which display Q Replication publisher KPIs grouped by hour. First, all data available in IBMQREP_CAPQMON is evaluated (can be limited with parameter max_mon_plot_range). Next, the most recent 20 days will be evaluated, lastly the most recent 5 days.<p>\n",
    "The plots show the maximum XMIT queue depth in the particular hour, and the summary of all rows published to MQ and the summary of all MQ messages sent by hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_perf_logrd executes a query which selects data from IBMQREP_CAPMON\n",
    "# and returns a pandas data frame. The CAPMON data is GROUPed BY hour(monitor_time)\n",
    "# by the query. In case max_mon_plot_range == 0, the query will retrieve all available data \n",
    "# from CAPQMON. If max_mon_plot_range > 0, the CAPQMON data will be limited to the recent\n",
    "# max_mon_plot_range days\n",
    "\n",
    "if max_mon_plot_range == -1:              \n",
    "    print('INFO: Evaluating all available CAPQMON data') \n",
    "else:   \n",
    "    print('INFO: Limiting the CAPQMON data to ' + str(max_mon_plot_range) + ' days.')\n",
    "\n",
    "capqmon_publ = get_perf_publ(connection,max_mon_plot_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG - print sample data of the data frame retrieved from APPLYMON\n",
    "if debug:\n",
    "   print(capqmon_publ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: What if data fame is empty (test)\n",
    "\n",
    "# Determine the date of max(monitor_time). This is used when only a subset (e.g., most recent\n",
    "# 5 days of data) is displayed later. Could be that the Notebook is used to evaluate saved \n",
    "# APPLYMON data, so that today() - n days would have no data. \n",
    "maxmontime = capqmon_publ['monitor_date'].max()\n",
    "maxmondate = datetime.strptime(maxmontime[:10], \"%Y-%m-%d\")\n",
    "\n",
    "maxmontime = capqmon_publ['monitor_date'].min()\n",
    "maxmondate = datetime.strptime(maxmontime[:10], \"%Y-%m-%d\")\n",
    "\n",
    "print('INFO: CAPMON' + ' [' + str(minmondate)[:10] + ' - ' + str(maxmondate)[:10] + ']') \n",
    "print()\n",
    "\n",
    "# Determination of the number of distinct receive queues in the result set\n",
    "numqs = len(capqmon_publ.sendq.unique())\n",
    "\n",
    "print('INFO: numqs=' + str(numqs))\n",
    "\n",
    "# print the distinct names and data ranges of the queues\n",
    "for i in range(0,numqs):\n",
    "    minmontimeq = capqmon_publ[capqmon_publ.sendq == capqmon_publ.sendq.unique()[i]]['monitor_date'].min()\n",
    "    maxmontimeq = capqmon_publ[capqmon_publ.sendq == capqmon_publ.sendq.unique()[i]]['monitor_date'].max()\n",
    "    minmondateq = datetime.strptime(minmontimeq[:10], \"%Y-%m-%d\")                \n",
    "    maxmondateq = datetime.strptime(maxmontimeq[:10], \"%Y-%m-%d\")        \n",
    "    print('INFO: ' + capqmon_publ.sendq.unique()[i] + ' [' + str(minmondateq)[:10] + ' - ' \n",
    "                   + str(maxmondateq)[:10] + ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All available data from IBMQREP_CAPQMON (max. <i>max_mon_plot_range</i> days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figure (one plot per queue) with all available data   \n",
    "\n",
    "# deltadays = 0 means all available data of the data frame\n",
    "deltadays = max_mon_plot_range\n",
    "if deltadays == -1:\n",
    "    date_max_days_ago = minmondate\n",
    "else:\n",
    "    date_max_days_ago = maxmondate - timedelta(days=deltadays)\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "    print('DEBUG: date_max_days_ago.strftime(\"%Y-%m-%d\"): ' + date_max_days_ago.strftime(\"%Y-%m-%d\"))        \n",
    "    \n",
    "if deltadays == -1:\n",
    "    print('INFO: Plotting range: All available data from ' + minmondate.strftime(\"%Y-%m-%d\") \n",
    "                                                           + ' up to ' + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "else:\n",
    "    print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                           + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                           + maxmondate.strftime(\"%Y-%m-%d\"))    \n",
    "    \n",
    "# The function plot_capmon creates a figure with n plots (n = number of queues) from the \n",
    "# data frame capqmon_lat\n",
    "# The hight of the following figures (calculated in plot_capqmon) depends on the number of distinct \n",
    "# receive queues. The more queues, the less space per individual queue (to limit the size of the figure)\n",
    "capqmon_plt1 = plot_capqmon(capqmon_publ,numqs,deltadays)\n",
    "capqmon_plt1.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent 20 days from IBMQREP_CAPQMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in - Same figure as above, with data of the last 20 days only (maxmondate - 20 days)\n",
    "\n",
    "# display 20 days of data only\n",
    "deltadays = 20\n",
    "# old: date_20_days_ago = date.today() - timedelta(days=deltadays)\n",
    "date_20_days_ago = maxmondate - timedelta(days=deltadays)\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "   print('DEBUG: date_20_days_ago.strftime(\"%m/%d/%Y\"): ' + date_20_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                       + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                       + maxmondate.strftime(\"%Y-%m-%d\"))    \n",
    "    \n",
    "# New data frame - limited by the calculated data range\n",
    "#   - reset_index was introduced to guarantee xticks in the plot\n",
    "capqmon_publ_20 = capqmon_publ[capqmon_publ.monitor_date \n",
    "                               >= date_20_days_ago.strftime(\"%Y-%m-%d\")].reset_index(drop=True)\n",
    "\n",
    "# The limited data could have a different number of queues\n",
    "# calc_fig_height remains as calculated before\n",
    "numqs = len(capqmon_publ_20.sendq.unique())\n",
    "\n",
    "if numqs == 0:\n",
    "    # Data frame could be empty\n",
    "    print('No data available to display with MONITOR_TIME > ' + date_20_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "else:\n",
    "    capqmon_plt2 = plot_capqmon(capqmon_publ_20,numqs,deltadays)\n",
    "    capqmon_plt2.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent 5 days from IBMQREP_CAPQMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in - Same figure as above, with data of the last 5 days only (maxmondate - 5 days)\n",
    "\n",
    "# display 5 days of data only\n",
    "deltadays = 5\n",
    "\n",
    "# old: date_5_days_ago = date.today() - timedelta(days=deltadays)\n",
    "date_5_days_ago = maxmondate - timedelta(days=deltadays)\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "   print('DEBUG: date_20_days_ago.strftime(\"%m/%d/%Y\"): ' + date_20_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                       + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                       + maxmondate.strftime(\"%Y-%m-%d\"))    \n",
    "\n",
    "# New data frame - limited by the calculated data range \n",
    "#   - reset_index was introduced to guarantee xticks in the plot\n",
    "capqmon_publ_5 = capqmon_publ[capqmon_publ.monitor_date \n",
    "                              >= date_5_days_ago.strftime(\"%Y-%m-%d\")].reset_index(drop=True)\n",
    "\n",
    "# The limited data could have a different number of queues\n",
    "# calc_fig_height remains as calculated before\n",
    "numqs = len(capqmon_publ_5.sendq.unique())\n",
    "\n",
    "if numqs == 0:\n",
    "    # Data frame could be empty\n",
    "    print('No data available to display with MONITOR_TIME > ' + date_5_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "else:    \n",
    "    capqmon_plt3 = plot_capqmon(capqmon_publ_5,numqs,deltadays)\n",
    "    capqmon_plt3.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qcap_details'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Capture details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Send Queue details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send queue details (IBMQREP_SENDQUEUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_sendq_details executes a query which selects detail data from IBMQREP_SENDQUEUES\n",
    "# and returns a pandas data frame\n",
    "df_queues = get_sendq_details(connection, capture_schema)\n",
    "\n",
    "# set index does not work\n",
    "df_queues.set_index(['sendq'],inplace=True)\n",
    "df_queues.sort_values(['sendq'], ascending=[True], inplace=True)\n",
    "\n",
    "# printing the data frame\n",
    "df_queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qsubs_details'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subscription details (IBMQREP_SUBS). Use pixiedust options to filter the result set or to convert the table into a  graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "keyFields": "source_owner",
      "table_noschema": "true",
      "title": "Subscription details"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_subs_details executes a query which selects detail data from IBMQREP_SUBS\n",
    "# and returns a pandas data frame\n",
    "df_subs = get_subs_details(connection, capture_schema)\n",
    "\n",
    "#df_subs.set_index('subname',inplace=True)\n",
    "df_subs.sort_values(['subname'], ascending=[True], inplace=True)    \n",
    "\n",
    "# displaying the data frame using pixiedust\n",
    "display(df_subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qsubs_qa'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription quality assurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime error prevention for existing subscriptions. The following potential error situations are reported:\n",
    " <ul>\n",
    "  <li>C-TNF - Source table not found</li>\n",
    "  <li>C-CNF - Subscribed column does not exist in DB2</li>\n",
    "  <li>C-CNS - Existing source column not subscribed</li>\n",
    "  <li>C-DCC - Data capture flag missing for source table</li>    \n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_capture_anomylies executes the query 'qrep_check_subs_capture.sql' \n",
    "# (with language dependent result set) and returns a pandas data frame\n",
    "df_capqa = get_capture_anomylies(connection)\n",
    "\n",
    "df_capqa.drop(df_capqa.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# conditional formatting for column 'sev'\n",
    "df_capqa = (df_capqa.style\n",
    "    .applymap(sev_background, subset=['sev'])\n",
    "    .applymap(sev_foreground, subset=['sev'])\n",
    ")\n",
    "\n",
    "# printing the data frame\n",
    "df_capqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qcap_cntl'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Capture Control Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Capture parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stored Q Capture parameters (IBMQREP_CAPPARMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_capparms executes a query which selects detail data from IBMQREP_CAPPARMS\n",
    "# and returns a pandas data frame\n",
    "df_capparms = get_capparms(connection, capture_schema)\n",
    "\n",
    "# printing the data frame\n",
    "df_capparms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qcap_mon'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Capture CAPMON and CAPQMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the monitoring date range\n",
    "# - as lowest date:\n",
    "#      - in case custom_mon_start_date == -1 take current date - daterange days, otherweise custom_mon_start_date\n",
    "# - as highest date:\n",
    "#      - in case custom_mon_end_date == -1 take current date, otherweise custom_mon_start_date\n",
    "\n",
    "calc_mon_dates = calc_mon_start_end(custom_mon_start_date, custom_mon_end_date, default_mon_date_range)\n",
    "\n",
    "mon_start_date = calc_mon_dates[0]\n",
    "mon_end_date   = calc_mon_dates[1]\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "    print(\"Monitor Start Date: \" + mon_start_date)\n",
    "    print(\"Monitor End Date:   \" + mon_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true",
      "title": "Q Capture log read statistics (CAPMON)"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_capmon executes a query which selects detail data from IBMQREP_CAPMON\n",
    "# and returns a pandas data frame\n",
    "df_capmon = get_capmon(connection, capture_schema, mon_start_date, mon_end_date)\n",
    "\n",
    "df_capmon.set_index('monitor_time')\n",
    "\n",
    "# sort does not seem to work\n",
    "df_capmon.sort_values(['monitor_time'], ascending=False, inplace=True)\n",
    "\n",
    "# displaying the data frame using Pixiedust\n",
    "display(df_capmon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true",
      "title": "Q Capture MQ publishing statistics (CAPQMON)"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_capqmon executes a query which selects detail data from IBMQREP_CAPQMON\n",
    "# and returns a pandas data frame\n",
    "df_capqmon = get_capqmon(connection, capture_schema, mon_start_date, mon_end_date)\n",
    "\n",
    "# sort does not seem to work\n",
    "df_capqmon.sort_values(['monitor_time'], ascending=False, inplace=True)\n",
    "\n",
    "# displaying the data frame using Pixiedust\n",
    "display(df_capqmon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qcap_trace'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Capture message log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the n (num_messages) most recent runtime log messages from IBMQREP_CAPTRACE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "rowCount": "200",
      "table_noschema": "true",
      "title": "Q Capture Log Messages"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_captrace executes a query which selects detail data from IBMQREP_APPLYTRACE\n",
    "# and returns a pandas data frame\n",
    "df_captrace = get_captrace(connection, capture_schema, num_messages_trace)\n",
    "\n",
    "# sort does not seem to work\n",
    "df_captrace.sort_values(['trace_time'], ascending=False, inplace=True)\n",
    "\n",
    "# displaying the data frame using Pixiedust\n",
    "display(df_captrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>08.05.2019:</b> This is the initial release of the Jupyter Notebook for Q Capture monitoring. It is the beginning of a learning curve and uses various Python and Jupyter Notebook techniques such as:\n",
    " <ul>    \n",
    "   <li>Db2 Python libraries</li>\n",
    "   <li>Pandas data frames</li>\n",
    "   <li>Pixiedust for result set visualization</li>\n",
    "   <li>matplotlib for the graphical representation of performance statistics</li>\n",
    " </ul>    \n",
    "<b>12.07.2019:</b> Fixed not displayed xticks for plots with limited date ranges (20 days, 5 days) by resetting the index after filtering the data frame (<i>.reset_index(drop=True)</i>)<p>\n",
    "<b>02.12.2019:</b> Some queries (e.g., 'get_sendq_details') just retrieve the content of IBMQREP control tables. Previously, these SQL queries contained a list of columns (all columns). This was changed for multiple queries to first generate the list of columns from the Db2 catalog and then build and execute the query. This increases the robustness of the Notebook because with that feature it supports multiple control table architecture levels (prevents errors because of missing (optional) columns).<p>\n",
    "<b>09.11.2020:</b> Improved DEBUG messages<br>\n",
    "<b>09.11.2020:</b> Optimized tick density for performance figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback and ideas for improvement are welcome and can be sent to clenke@de.ibm.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
