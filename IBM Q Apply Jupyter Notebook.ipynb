{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  IBM Q Apply Jupyter Notebook\n",
    "Author: Christian Lenke, IBM<br>\n",
    "Version: 2020-11-09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content\n",
    "\n",
    "* [Preface](#intro)\n",
    "* [Introduction](#intro)\n",
    "<p>\n",
    "* [Installation, import, function definition](#preparation)\n",
    "  * [Environment Definition and Customization](#customization)\n",
    "  * [Get a connection to the Q Apply Server](#connect_qapp)\n",
    "<p>\n",
    "* [Q Apply Status overview](#overview_qapp)\n",
    "  * [General Q Apply overview](#overview_qapp)\n",
    "  * [Receive Queue state](#recvq)\n",
    "  * [Q Subscription state by Receive Queue](#qsubs_recvq)    \n",
    "  * [Q Subscription type by Receive Queue](#qsubs_type)        \n",
    "<p>\n",
    "* [Q Apply performance graphs](#qapp_performance_hour)\n",
    "  * [APPLYMON KPIs per hour](#qapp_performance_hour)    \n",
    "  * [APPLYMON KPIs per day](#qapp_performance_day)        \n",
    "  * [Detailed APPLYMON KPIs (one hour of data)](#qapp_performance_details)            \n",
    "<p>\n",
    "* [Status details](#qapp_details)\n",
    "  * [Receive Queue details](#qapp_details)\n",
    "  * [Q Subscription details](#qsubs_details)\n",
    "  * [Q Subscription quality assurance](#qsubs_qa)        \n",
    "<p>\n",
    "* [Q Apply Control Tables](#qapp_cntl)\n",
    "  * [APPLYPARMS](#qapp_cntl)\n",
    "  * [APPLYMON](#qapp_mon)\n",
    "  * [APPLYTRACE](#qapp_trace)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='intro'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter Notebook is sample code. No warranty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This set of Jupyter Notebook can be used to display status, performance, and health of an IBM Q Replication setup. The following components are provided:\n",
    " <ul>\n",
    "  <li>Q Capture Jupyter Notebook</li>\n",
    "  <li>Q Apply Jupyter Notebook (this Notebook)</li>\n",
    "  <li>Q Replication function library Jupyter Notebook</li>\n",
    "  <li>A set of SQL queries in files (asnmonitor) for status calculation and quality assurance</li>    \n",
    "</ul> \n",
    "The Notebooks display the content of the IBM Q Replication control tables. This includes an overall health summary for both Q Capture and Q Apply, performance graphs (throughput, latency, etc.), and control table details for both queues and subscriptions.<br>\n",
    "Start with the following:<br>\n",
    " <ol>\n",
    "  <li>Copy the set of SQL query files to a location in your environment</li>\n",
    "  <li>Cuctomize some of the SQL files depending on your environment (more details in the Q Replication function library Notebook)</li>\n",
    "  <li>Customize the Q Replication function library (details explained in that Notebook)</li>\n",
    "  <li>Customize the Q Capture and Q Apply Notebook (this Notebook) in section \"Environment Definition and Customization\" \n",
    "</ol> \n",
    "To better understand the Q Replication control tables and the SQL queries used, have a look at<br>\n",
    "<A HREF=\"https://developer.ibm.com/recipes/tutorials/q-replication-for-dbas/\">Q Replication for DBAs</A>,<br>\n",
    "<A HREF=\"https://www.ibm.com/support/knowledgecenter/en/SSTRGZ_11.4.0/com.ibm.swg.im.iis.repl.qrepl.doc/topics/iiyrqctbrcaplist.html\">Control tables at the Q Capture server</A>,<br> \n",
    "<A HREF=\"https://www.ibm.com/support/knowledgecenter/en/SSTRGZ_11.4.0/com.ibm.swg.im.iis.repl.qrepl.doc/topics/iiyrqctbrapplist.html\">Control tables at the Q Apply server</A>, or <br>\n",
    "<A HREF=\"https://www.ibm.com/support/knowledgecenter/en/SSTRGZ_11.4.0/com.ibm.swg.im.iis.db.repl.intro.doc/topics/iiyrqinfroadmap.html\">Q Replication Information Roadmap (IBM Knowledge Center)</A>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='preparation'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation, import, function definition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all the \"IBM Q Replication Monitoring Jupyter Library.ipynb\" is run. It imports all required libraries (SQLAlchemy, pandas, pixiedust, ...) and defines functions used in this Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"IBM Q Replication Monitoring Jupyter Library.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='customization'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Definition and Customization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BEFORE YOU START define your environment here. Specify your individual values for all variables in the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specifying the Db2 driver (don't change)\n",
    "db2_driver='ibm_db_sa'\n",
    "\n",
    "# Define your Q Apply Schema. All queries selecting data from the Q Replication control tables \n",
    "# have been coded schemaless, the schema needs to be declared once here.\n",
    "apply_schema = 'ASN'\n",
    "# apply_schema = 'LSN'\n",
    "\n",
    "# Database alias of the Q Apply Server (Db2 LUW database name or Db2 z/OS location name)\n",
    "# db2alias = 'BLU_TGT'\n",
    "# db2alias = 'ASCIIDB'\n",
    "db2alias = 'TARGETDB'\n",
    "\n",
    "# Setting the connection variables for the Q Apply server (usually the Q Replication target database)\n",
    "# Host name or ip-address of the Q Apply Server\n",
    "db2host  = 'localhost'\n",
    "# Db2 port of the Q Apply Server (defined as char)\n",
    "db2port  = 50000\n",
    "\n",
    "# User id privileged to read the Q Apply control tables\n",
    "db2user  = 'REPLADM'\n",
    "# You will be prompted to type in your password\n",
    "db2password = getpass.getpass('Password for database ' + db2alias + ': '); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Switch to control debug messages. False: No debug messages; True: Some debug messages will be printed\n",
    "# debug = True\n",
    "debug = False\n",
    "\n",
    "# Display all columns when showing a data frame\n",
    "pandas.set_option('display.max_columns', None)\n",
    "\n",
    "# Define the date range for plotting performance data from IBMQREP_APPLYMON (plots grouped by hour)\n",
    "# Default: 60 (Retrieve only 60 days of Monitor data for plotting)\n",
    "# If you want to retrieve all available data, set max_mon_plot_range = -1\n",
    "# max_mon_plot_range = -1\n",
    "max_mon_plot_range = 60\n",
    "\n",
    "# Define the start date for plotting the IBMQREP_APPLYMON details (ungrouped)\n",
    "# One hour of APPLYMON data will be plotted, starting from the defined start_ts here\n",
    "# Default: 'max' (Last hour of available data.) \n",
    "# A dedicated Db2 timestamp can be specified alternatively\n",
    "# start_ts_mon_plot_details = 'max'\n",
    "start_ts_mon_plot_details = '2020-10-28-17.10.00.000000'\n",
    "\n",
    "# Define the number of most recent messages messages to be retrieved from IBMQREP_APPLYTRACE. \n",
    "# Default: 200\n",
    "# If you want to retrieve all available data, set num_messages_trace = -1\n",
    "num_messages_trace = -1\n",
    "#num_messages_trace = 200\n",
    "\n",
    "# Define the date range for fetching monitor information from IBMQREP_APPLYMON (display as table),\n",
    "# specified as number of days. Default: 10  \n",
    "default_mon_date_range = 10\n",
    "# Custom range: -1 means from oldest available (start) to most recent (end).\n",
    "# Alternatively, specify timestamp in Db2 format\n",
    "# custom_mon_start_date  = '2018-11-02-10.00.00.000000'\n",
    "custom_mon_start_date  = -1\n",
    "custom_mon_end_date    = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the validity of some parms\n",
    "check_minus_1_or_positive_int('max_mon_plot_range', max_mon_plot_range)        \n",
    "check_minus_1_or_positive_int('num_messages_trace', num_messages_trace)        \n",
    "check_positive_int('default_mon_date_range', default_mon_date_range) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='connect_qapp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a connection to the Q Apply Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Q Apply Server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = get_connection(db2_driver, db2user, db2password, db2host, str(db2port), db2alias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the CURRENT SCHEMA to the APPLY_SCHEMA. All queries executed thereafter are schemaless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the connection the SCHEMA is set to the Q Apply schema\n",
    "connection.execute(\"SET CURRENT SCHEMA = '\" + apply_schema + \"'\")\n",
    "\n",
    "print(\"INFO: CURRENT SCHEMA = '\" + apply_schema + \"'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='overview_qapp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Apply Status overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General status overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first query displays the overall status of the Q Apply Server. The result set displays messages of the following types:\n",
    " <ul>\n",
    "  <li>A-LAT: Is Q Apply running or not / is the latency as expected (threshold needs to be set in 'qrep_monitor_apply.sql')</li>\n",
    "    <ul>    \n",
    "        <li>ERROR: Q Apply not running or latency error threshold exceeded</li>\n",
    "        <li>WARNING: Q Apply latency warning threshold exceeded</li>\n",
    "        <li>INFO: Q Apply up and running and latency threshold ok</li>        \n",
    "    </ul>            \n",
    "  <li>A-RQU: Receive queue status, displayed for each receive queue.</li>\n",
    "    <ul>    \n",
    "        <li>ERROR: Receive Queue inactive due to an error</li>\n",
    "        <li>INFO: Receive Queue active</li>            \n",
    "    </ul>                    \n",
    "  <li>A-SUB: Subscription status.</li>\n",
    "    <ul>    \n",
    "        <li>ERROR: Subscription not active</li>\n",
    "    </ul>                    \n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_apply_status executes the query 'qrep_monitor_apply.sql' \n",
    "# (with language dependent result set) and returns a pandas data frame\n",
    "df_appstate = get_apply_status(connection)\n",
    "\n",
    "# drop column 'CURRENT_SERVER'\n",
    "df_appstate.drop(df_appstate.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# conditional formatting for column 'sev'\n",
    "df_appstate = (df_appstate.style\n",
    "    .applymap(sev_background, subset=['sev'])\n",
    "    .applymap(sev_foreground, subset=['sev'])\n",
    ")\n",
    "\n",
    "# printing the data frame\n",
    "df_appstate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='recvq'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall receive queue state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of active receive queues (green) vs. number of inactive receive queues (red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_apply_status executes a query which counts active vs. inactive queues\n",
    "# and returns a pandas data frame\n",
    "df_qstate = get_recvq_state(connection)  \n",
    "\n",
    "df_qstate.set_index('queues',inplace=True)\n",
    "\n",
    "# plotting a bar chart\n",
    "qpl = df_qstate.plot.barh(stacked=True,color=['green', 'red'], \n",
    "                          title=\"Active vs. inactive receive queues\",\n",
    "                          figsize=(10,2))\n",
    "\n",
    "qpl.set_xlabel(\"Number of queues\")\n",
    "myvar = qpl.set_ylabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qsubs_recvq'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription STATE by receive queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of active subscriptions (green) vs. number of inactive subscriptions (red) per receive queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The function get_substate_by_recvq executes a query which counts active vs. inactive queues\n",
    "# and returns a pandas data frame\n",
    "df_q = get_substate_by_recvq(connection)\n",
    "\n",
    "# Determination of the number of distinct receive queues in the result set\n",
    "numqs = len(df_q.recvq.unique())\n",
    "\n",
    "# The hight of the following bar charts depends on the number of distinct receive queues.\n",
    "# The more queues, the less space per individual queue (to limit the size of the plot)\n",
    "if numqs >=20:\n",
    "    calc_fig_height = numqs / 2\n",
    "if numqs <=2:\n",
    "    calc_fig_height = numqs * 2\n",
    "else:\n",
    "    calc_fig_height =  numqs\n",
    "\n",
    "df_q.set_index('recvq',inplace=True) \n",
    "\n",
    "# plotting a bar chart\n",
    "sqpl = df_q.plot.barh(stacked=True,color=['green', 'red'],\n",
    "                       title=\"Number of active vs. inactive subs per receive queue\",\n",
    "                       figsize=(15,calc_fig_height))\n",
    "\n",
    "sqpl.set_xlabel(\"Number of subs\")\n",
    "myvar = sqpl.set_ylabel(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qsubs_type'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription TYPE Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of Q Subscription target types per Receive Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_subtype_by_recvq executes a query which counts available subscriptions \n",
    "# by type and returns a pandas data frame\n",
    "df_st = get_subtype_by_recvq(connection)\n",
    "\n",
    "# DEBUG - print sample data of the data frame retrieved from APPLYMON\n",
    "if debug:\n",
    "    print(df_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determination of the number of distinct receive queues in the result set\n",
    "numqs = len(df_st.recvq.unique())\n",
    "\n",
    "# The following plot prints a pie for each queue. Two queues in the same row (always fig with 2 columns)\n",
    "# With anaconda 3 'round' does an closest even round. round(1.5)=2 and round(2.5)=2. Therefore useless here.\n",
    "# figrows = round(numqs / 2)\n",
    "# The number of rows is the rounded number of queues devided by 2.\n",
    "figrows = int((numqs/2)+0.5)\n",
    "\n",
    "print('INFO: Figure will have ' + str(numqs) + ' pie chart(s) in ' + str(figrows) + ' row(s) and ' \n",
    "                                + '2 columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function plot_types creates a figure with n donut plots (n = number of queues) to display \n",
    "# the different subscription types per queue\n",
    "subtypeplot = plot_types(df_st,numqs,figrows)\n",
    "subtypeplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qapp_performance_hour'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Apply Performance Graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply throughput statistics per hour (rows_processed, latency, monster trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following codes creates plots which display Q Replication performance KPIs grouped by hour. First, all data available in IBMQREP_APPLYMON is evaluated (can be limited with parameter <i>max_mon_plot_range</i>). Next, the most recent 20 days will be evaluated, lastly the most recent 5 days. For each section (all, 20 days, 5 days) a separate plot is shown for each receive queue.<p>\n",
    "The plots show the maximum latency values seen in the particular hour, and the summary of all processed rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_perf_applymon executes a query which selects data from IBMQREP_APPLYMON\n",
    "# and returns a pandas data frame. The APPLYMON data is GROUPed BY hour(monitor_time)\n",
    "# by the query. In case max_mon_plot_range == -1, the query will retrieve all available data \n",
    "# from APPLYMON. If max_mon_plot_range > 0, the APPLYMON data will be limited to the recent\n",
    "# max_mon_plot_range days\n",
    "\n",
    "if max_mon_plot_range == -1:              \n",
    "    print('INFO: Evaluating all available APPLYMON data') \n",
    "else:   \n",
    "    print('INFO: Limiting the APPLYMON data to ' + str(max_mon_plot_range) + ' days.')\n",
    "              \n",
    "applymon_lat = get_perf_applymon(connection, max_mon_plot_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG - print sample data of the data frame retrieved from APPLYMON\n",
    "if debug:\n",
    "    print(applymon_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the date of max(monitor_time). This is used when only a subset (e.g., most recent\n",
    "# 5 days of data) is displayed later. Could be that the Notebook is used to evaluate saved \n",
    "# APPLYMON data, so that today() - n days would have no data. \n",
    "maxmontime = applymon_lat['monitor_date'].max()\n",
    "maxmondate = datetime.strptime(maxmontime[:10], \"%Y-%m-%d\")\n",
    "\n",
    "minmontime = applymon_lat['monitor_date'].min()\n",
    "minmondate = datetime.strptime(minmontime[:10], \"%Y-%m-%d\")\n",
    "\n",
    "if debug:\n",
    "    print('DEBUG: minmondate.global=' + str(minmondate)[:10])\n",
    "    print('DEBUG: maxmondate.global=' + str(maxmondate)[:10])\n",
    "    print()\n",
    "\n",
    "# Determination of the number of distinct receive queues in the result set\n",
    "numqs = len(applymon_lat.recvq.unique())\n",
    "\n",
    "print('INFO: Number of queues=' + str(numqs))\n",
    "\n",
    "# DEBUG - print the distinct names of the queues\n",
    "if debug:\n",
    "   for i in range(0,numqs):\n",
    "        minmontimeq = applymon_lat[applymon_lat.recvq == applymon_lat.recvq.unique()[i]]['monitor_date'].min()\n",
    "        maxmontimeq = applymon_lat[applymon_lat.recvq == applymon_lat.recvq.unique()[i]]['monitor_date'].max()\n",
    "        minmondateq = datetime.strptime(minmontimeq[:10], \"%Y-%m-%d\")                \n",
    "        maxmondateq = datetime.strptime(maxmontimeq[:10], \"%Y-%m-%d\")        \n",
    "        print('INFO: ' + applymon_lat.recvq.unique()[i] + ' [' + str(minmondateq)[:10] + ' - ' + str(maxmondateq)[:10] + ']') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All available data from IBMQREP_APPLYMON (max. <i>max_mon_plot_range</i> days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figure (one plot per queue) with all available data   \n",
    "\n",
    "# deltadays = -1 means all available data of the data frame\n",
    "deltadays = max_mon_plot_range\n",
    "if deltadays == -1:\n",
    "    date_max_days_ago = minmondate\n",
    "else:\n",
    "    date_max_days_ago = maxmondate - timedelta(days=deltadays)\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "    if deltadays == -1:\n",
    "        print('INFO: Plotting range: All available data from ' + minmondate.strftime(\"%Y-%m-%d\") \n",
    "                                                           + ' up to ' + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "    else:\n",
    "        print('DEBUG: date_max_days_ago.strftime(\"%Y-%m-%d\"): ' + date_max_days_ago.strftime(\"%Y-%m-%d\"))        \n",
    "        print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                           + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                           + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# The function plot_lat creates a figure with n plots (n = number of queues) from the \n",
    "# data frame applymon_lat\n",
    "# The hight of the following figures (calculated in plot_lat) depends on the number of distinct \n",
    "# receive queues. The more queues, the less space per individual queue (to limit the size of the figure)\n",
    "if numqs == 0:\n",
    "    # Data frame could be empty\n",
    "    print('WARNING: No data available to display.')\n",
    "else:    \n",
    "    applymon_plt60 = plot_lat(applymon_lat,numqs,deltadays,'by_hour')\n",
    "    applymon_plt60.show()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent 20 days from IBMQREP_APPLYMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in - Same figure as above, with data of the last 20 days only (maxmondate - 20 days)\n",
    "\n",
    "# display 20 days of data only\n",
    "deltadays = 20\n",
    "# old: date_20_days_ago = date.today() - timedelta(days=deltadays)\n",
    "date_20_days_ago = maxmondate - timedelta(days=deltadays)\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "   print('DEBUG: date_20_days_ago.strftime(\"%Y-%m-%d\"): ' + date_20_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "   print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                           + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                           + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "    \n",
    "# New data frame - limited by the calculated data range\n",
    "#   - reset_index was introduced to guarantee xticks in the plot\n",
    "applymon_lat_20 = applymon_lat[applymon_lat.monitor_date \n",
    "                               >= date_20_days_ago.strftime(\"%Y-%m-%d\")].reset_index(drop=True)\n",
    "\n",
    "# The limited data could have a different number of queues\n",
    "# calc_fig_height remains as calculated before\n",
    "numqs = len(applymon_lat_20.recvq.unique())\n",
    "\n",
    "if numqs == 0:\n",
    "    # Data frame could be empty\n",
    "    print('WARNING: No data available to display with MONITOR_TIME > ' + date_20_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "else:\n",
    "    applymon_plt20 = plot_lat(applymon_lat_20,numqs,deltadays,'by_hour')\n",
    "    applymon_plt20.show()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent 5 days from IBMQREP_APPLYMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in - Same figure as above, with data of the last 5 days only (maxmondate - 5 days)\n",
    "\n",
    "# display 5 days of data only\n",
    "deltadays = 5\n",
    "\n",
    "# old: date_5_days_ago = date.today() - timedelta(days=deltadays)\n",
    "date_5_days_ago = maxmondate - timedelta(days=deltadays)\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "    print('DEBUG: date_5_days_ago.strftime(\"%Y-%m-%d\"): ' + date_5_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "    print('INFO: Plotting range: Maximum of most recent '  + str(deltadays) + ' days between ' \n",
    "                                                           + minmondate.strftime(\"%Y-%m-%d\") + ' and ' \n",
    "                                                           + maxmondate.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "\n",
    "# New data frame - limited by the calculated data range \n",
    "#   - reset_index was introduced to guarantee xticks in the plot\n",
    "applymon_lat_5 = applymon_lat[applymon_lat.monitor_date \n",
    "                              >= date_5_days_ago.strftime(\"%Y-%m-%d\")].reset_index(drop=True)  \n",
    "\n",
    "# The limited data could have a different number of queues\n",
    "# calc_fig_height remains as calculated before\n",
    "numqs = len(applymon_lat_5.recvq.unique())\n",
    "\n",
    "if numqs == 0:\n",
    "    # Data frame could be empty\n",
    "    print('WARNING: No data available to display with MONITOR_TIME > ' + date_5_days_ago.strftime(\"%Y-%m-%d\"))\n",
    "else:    \n",
    "    applymon_plt5 = plot_lat(applymon_lat_5,numqs,deltadays,'by_hour')\n",
    "    applymon_plt5.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qapp_performance_day'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply throughput statistics per day - all available data from APPLYMON (rows_processed, latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following codes creates plots which display Q Replication performance KPIs grouped by day. All data available in IBMQREP_APPLYMON is evaluated. The plots show the average latency values for a day, and the summary of all processed rows. A separate plot is shown for each receive queue,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_perf_applymon_day executes a query which selects data from IBMQREP_APPLYMON\n",
    "# and returns a pandas data frame. The APPLYMON data is GROUPed BY day(monitor_time)\n",
    "# by the query. The query will retrieve all available data from APPLYMON.\n",
    "\n",
    "print('INFO: Evaluating all available APPLYMON data') \n",
    "              \n",
    "applymon_lat_day = get_perf_applymon_day(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG - print sample data of the data frame retrieved from APPLYMON\n",
    "if debug:\n",
    "   print(applymon_lat_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determination of the number of distinct receive queues in the result set\n",
    "numqs = len(applymon_lat_day.recvq.unique())\n",
    "\n",
    "print('INFO: Number of queues=' + str(numqs))\n",
    "\n",
    "# DEBUG - print the number of queues and the distinct names of the queues\n",
    "if debug:\n",
    "   for i in range(0,numqs):\n",
    "       print('DEBUG: ' + applymon_lat_day.recvq.unique()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot figure (one plot per queue) with all available data   \n",
    "\n",
    "deltadays = -1\n",
    "\n",
    "# The function plot_lat creates a figure with n plots (n = number of queues) from the \n",
    "# data frame applymon_lat\n",
    "# The hight of the following figures (calculated in plot_lat) depends on the number of distinct \n",
    "# receive queues. The more queues, the less space per individual queue (to limit the size of the figure)\n",
    "if numqs == 0:\n",
    "    # Data frame could be empty\n",
    "    print('No data available to display')\n",
    "else:    \n",
    "    applymon_plt_day = plot_lat(applymon_lat_day,numqs,deltadays,'by_day')\n",
    "    applymon_plt_day.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qapp_performance_details'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Apply throughput statistics (APPLYMON) - one hour of available data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function get_perf_applymon_detail executes a query which selects data from IBMQREP_APPLYMON\n",
    "# and returns a pandas data frame. The query will retrieve one hour of data from APPLYMON, starting \n",
    "# at start_ts_mon_plot_details (defined in the defaults section of this Notebook). If \n",
    "# start_ts_mon_plot_details == 'max', the last hour of available data will be analyzed\n",
    "\n",
    "applymon_details = get_perf_applymon_detail(connection, start_ts_mon_plot_details)\n",
    "mi = get_monitor_interval(connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG - print sample data of the data frame retrieved from APPLYMON\n",
    "if debug:\n",
    "   print(applymon_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determination of the number of distinct receive queues in the result set\n",
    "numqs = len(applymon_details.recvq.unique())\n",
    "\n",
    "print('INFO: Number of queues=' + str(numqs))\n",
    "\n",
    "# DEBUG - print the number of queues and the distinct names of the queues\n",
    "if debug:\n",
    "    for i in range(0,numqs):\n",
    "       print('DEBUG: ' + applymon_details.recvq.unique()[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    }
   },
   "outputs": [],
   "source": [
    "# Plot figure (one plot per queue), 1 hour of data\n",
    "print('INFO: MONITOR_INTERVAL=' + str(mi) + ' milliseconds (' + str(mi/1000) + ' seconds)')\n",
    "\n",
    "# The function plot_lat_details creates a figure with n plots (n = number of queues) from the \n",
    "# data frame applymon_details\n",
    "# The hight of the following figures (calculated in plot_lat_details) depends on the number of distinct \n",
    "# receive queues. The more queues, the less space per individual queue (to limit the size of the figure)\n",
    "if numqs == 0:\n",
    "    # Data frame could be empty\n",
    "    print('No data available to display with MONITOR_TIME > ' + start_ts_mon_plot_details)\n",
    "else:    \n",
    "    applymon_plt_details = plot_lat_details(applymon_details,numqs,start_ts_mon_plot_details,'by_interval')\n",
    "    applymon_plt_details.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qapp_details'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Apply details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Receive Queue details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Receive queue details (IBMQREP_RECVQUEUES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_recvq_details executes a query which selects detail data from IBMQREP_RECVQUEUES\n",
    "# and returns a pandas data frame\n",
    "df_queues = get_recvq_details(connection, apply_schema)\n",
    "\n",
    "df_queues.set_index(['sendq'],inplace=True)\n",
    "df_queues.sort_values(['sendq'], ascending=[True], inplace=True)\n",
    "\n",
    "# printing the data frame\n",
    "df_queues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qsubs_details'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subscription details (IBMQREP_TARGETS). Use pixiedust options to filter the result set or to convert the table into a  graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "keyFields": "source_owner",
      "table_noschema": "true",
      "title": "Subscription details"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_targets_details executes a query which selects detail data from IBMQREP_TARGETS\n",
    "# and returns a pandas data frame\n",
    "df_subs = get_targets_details(connection, apply_schema)\n",
    "\n",
    "df_subs.sort_values(['subname'], ascending=[True], inplace=True)    \n",
    "\n",
    "# displaying the data frame using pixiedust\n",
    "display(df_subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qsubs_qa'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscription quality assurance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Runtime error prevention for existing subscriptions. The following potential error situations are reported:\n",
    " <ul>\n",
    "  <li>A-TNF - Target table not found</li>\n",
    "  <li>A-CNF - Subscribed column does not exist in DB2</li>\n",
    "  <li>A-CNS - Existing target column not subscribed</li>\n",
    "  <li>A-GRA - Target table grant missing for Apply user</li>\n",
    "  <li>A-RIP - Sub for RI parent of a replicated RI child missing</li>\n",
    "  <li>A-RIC - Sub for RI child of a replicated RI parent missing</li>\n",
    "  <li>A-BID - Before image column has different data type than after image column</li>\n",
    "</ul> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_apply_anomylies executes the query 'qrep_check_subs_apply.sql' \n",
    "# (with language dependent result set) and returns a pandas data frame\n",
    "df_appqa = get_apply_anomylies(connection)\n",
    "\n",
    "df_appqa.drop(df_appqa.columns[2], axis=1, inplace=True)\n",
    "\n",
    "# conditional formatting for column 'sev'\n",
    "df_appqa = (df_appqa.style\n",
    "    .applymap(sev_background, subset=['sev'])\n",
    "    .applymap(sev_foreground, subset=['sev'])\n",
    ")\n",
    "\n",
    "# printing the data frame\n",
    "df_appqa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qapp_cntl'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q Apply Control Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Apply parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stored Q Apply parameters (IBMQREP_APPLYPARMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_applyparms executes a query which selects detail data from IBMQREP_APPLYPARMS\n",
    "# and returns a pandas data frame\n",
    "df_applyparms = get_applyparms(connection, apply_schema)\n",
    "\n",
    "# printing the data frame\n",
    "df_applyparms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qapp_mon'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Apply APPLYMON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the monitoring date range\n",
    "# - as lowest date:\n",
    "#      - in case custom_mon_start_date == -1 take current date - daterange days, otherweise custom_mon_start_date\n",
    "# - as highest date:\n",
    "#      - in case custom_mon_end_date == -1 take current date, otherweise custom_mon_start_date\n",
    "\n",
    "# The function calc_mon_start_end calculates the interval to retrieve from APPLYMON from \n",
    "# custom_mon_start_date, custom_mon_end_date, default_mon_date_range. It returns an array with 2 timestamps\n",
    "calc_mon_dates = calc_mon_start_end(custom_mon_start_date, custom_mon_end_date, default_mon_date_range)\n",
    "\n",
    "mon_start_date = calc_mon_dates[0]\n",
    "mon_end_date = calc_mon_dates[1]\n",
    "\n",
    "# Debug\n",
    "if debug:\n",
    "    print(\"Monitor Start Date: \" + mon_start_date)\n",
    "    print(\"Monitor End Date:   \" + mon_end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "table_noschema": "true",
      "title": "Q Apply statistics (APPLYMON)"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_applymon executes a query which selects detail data from IBMQREP_APPLYMON\n",
    "# and returns a pandas data frame\n",
    "df_applymon = get_applymon(connection, apply_schema, mon_start_date, mon_end_date)\n",
    "\n",
    "df_applymon.set_index('monitor_time')\n",
    "\n",
    "# sort does not seem to work\n",
    "df_applymon.sort_values(['monitor_time'], ascending=False, inplace=True)\n",
    "\n",
    "# displaying the data frame using Pixiedust\n",
    "display(df_applymon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='qapp_trace'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q Apply message log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the n (num_messages_trace) most recent runtime log messages from IBMQREP_APPLYTRACE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pixiedust": {
     "displayParams": {
      "handlerId": "tableView",
      "rowCount": "200",
      "table_noschema": "true",
      "title": "Q Apply Log Messages"
     }
    }
   },
   "outputs": [],
   "source": [
    "# The function get_applytrace executes a query which selects detail data from IBMQREP_APPLYTRACE\n",
    "# and returns a pandas data frame\n",
    "df_applytrace = get_applytrace(connection, apply_schema, num_messages_trace)\n",
    "\n",
    "# sort does not seem to work\n",
    "df_applytrace.sort_values(['trace_time'], ascending=False, inplace=True)\n",
    "\n",
    "# displaying the data frame using Pixiedust\n",
    "display(df_applytrace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#top)\n",
    "<a id='end'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Release Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>08.05.2019:</b> This is the initial release of the Jupyter Notebook for Q Apply monitoring. It is the beginning of a learning curve and uses various Python and Jupyter Notebook techniques such as:\n",
    " <ul>    \n",
    "   <li>Db2 Python libraries</li>\n",
    "   <li>Pandas data frames</li>\n",
    "   <li>Pixiedust for result set visualization</li>\n",
    "   <li>matplotlib for the graphical representation of performance statistics</li>\n",
    " </ul>    \n",
    "<b>17.06.2019:</b> Added another plot: one hour of detailed APPLYMON data. By default, the most recent hour of available APPLYMON data is displayed. If you want to display a certain hour, change the variable <i>start_ts_mon_plot_details</i> in the customization section at the top of the Notebook.<p>\n",
    "<b>12.07.2019:</b> Fixed not displayed xticks for plots with limited date ranges (20 days, 5 days) by resetting the index after filtering the data frame (<i>.reset_index(drop=True)</i>)<p>\n",
    "<b>23.07.2019:</b> Added another plot: Donut charts per receive queue to visualize the different subsciption types\n",
    "per queue.<p>\n",
    "<b>02.12.2019:</b> Some queries (e.g., 'get_recvq_details') just retrieve the content of IBMQREP control tables. Previously, these SQL queries contained a list of columns (all columns). This was changed for multiple queries to first generate the list of columns from the Db2 catalog and then build and execute the query. This increases the robustness of the Notebook because with that feature it supports multiple control table architecture levels (prevents errors because of missing (optional) columns).<p>\n",
    "<b>12.12.2019:</b> Performance KPIs by day - changed from max latency to average latency<p>\n",
    "<b>09.11.2020:</b> Performance KPIs by day - changed back to max latency<br>\n",
    "<b>09.11.2020:</b> Improved DEBUG messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feedback and ideas for improvement are welcome and can be sent to clenke@de.ibm.com"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
